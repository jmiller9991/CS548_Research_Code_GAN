{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Nov 12 20:39:06 2020       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 435.21       Driver Version: 435.21       CUDA Version: 10.1     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce RTX 208...  Off  | 00000000:3B:00.0 Off |                  N/A |\r\n",
      "| 28%   42C    P8    20W / 250W |      7MiB / 11019MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  GeForce RTX 208...  Off  | 00000000:5E:00.0 Off |                  N/A |\r\n",
      "| 27%   35C    P8    20W / 250W |      7MiB / 11019MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   2  GeForce RTX 208...  Off  | 00000000:AF:00.0 Off |                  N/A |\r\n",
      "| 27%   37C    P8    19W / 250W |     22MiB / 11019MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0      1707      G   /usr/lib/xorg/Xorg                             5MiB |\r\n",
      "|    1      1707      G   /usr/lib/xorg/Xorg                             5MiB |\r\n",
      "|    2      1707      G   /usr/lib/xorg/Xorg                             9MiB |\r\n",
      "|    2      1795      G   /usr/bin/gnome-shell                          10MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2019, NVIDIA CORPORATION. All rights reserved.\n",
    "#\n",
    "# This work is licensed under the Creative Commons Attribution-NonCommercial\n",
    "# 4.0 International License. To view a copy of this license, visit\n",
    "# http://creativecommons.org/licenses/by-nc/4.0/ or send a letter to\n",
    "# Creative Commons, PO Box 1866, Mountain View, CA 94042, USA.\n",
    "\n",
    "\"\"\"Minimal script for reproducing the figures of the StyleGAN paper using pre-trained generators.\"\"\"\n",
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "import dnnlib\n",
    "import dnnlib.tflib as tflib\n",
    "import ipywidgets as widgets\n",
    "from tqdm import tqdm\n",
    "#----------------------------------------------------------------------------\n",
    "# Helpers for loading and using pre-trained generators.\n",
    "\n",
    "url_ffhq        = '/home/firschj/src/CS548_Research_Code_GAN/stylegan2-ffhq-config-f.pkl' # karras2019stylegan-ffhq-1024x1024.pkl\n",
    "\n",
    "CACHE_DIR       = \"cache\"\n",
    "\n",
    "synthesis_kwargs = dict(output_transform=dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True), minibatch_size=8)\n",
    "\n",
    "_Gs_cache = dict()\n",
    "\n",
    "def load_Gs(url):\n",
    "    if url not in _Gs_cache:\n",
    "        if \"https://\" in url:\n",
    "            with dnnlib.util.open_url(url, cache_dir=CACHE_DIR) as f:\n",
    "                _G, _D, Gs = pickle.load(f)\n",
    "        else:\n",
    "            with open(url, \"rb\") as f:\n",
    "                _G, _D, Gs = pickle.load(f)\n",
    "        _Gs_cache[url] = Gs\n",
    "    return _Gs_cache[url]\n",
    "\n",
    "\n",
    "def draw_uncurated_result_figure(png, Gs, cx, cy, cw, ch, rows, lods, seed):\n",
    "    latents = np.random.RandomState(seed).randn(sum(rows * 2**lod for lod in lods), Gs.input_shape[1])\n",
    "    images = Gs.run(latents, None, **synthesis_kwargs) # [seed, y, x, rgb]\n",
    "\n",
    "    canvas = PIL.Image.new('RGB', (sum(cw // 2**lod for lod in lods), ch * rows), 'white')\n",
    "    image_iter = iter(list(images))\n",
    "    for col, lod in enumerate(lods):\n",
    "        for row in range(rows * 2**lod):\n",
    "            image = PIL.Image.fromarray(next(image_iter), 'RGB')\n",
    "            image = image.crop((cx, cy, cx + cw, cy + ch))\n",
    "            image = image.resize((cw // 2**lod, ch // 2**lod), PIL.Image.ANTIALIAS)\n",
    "            canvas.paste(image, (sum(cw // 2**lod for lod in lods[:col]), row * ch // 2**lod))\n",
    "    return canvas\n",
    "\n",
    "\n",
    "def draw_style_mixing_figure(png, Gs, w, h, src_seeds, dst_seeds, style_ranges):\n",
    "    src_latents = np.stack(np.random.RandomState(seed).randn(Gs.input_shape[1]) for seed in src_seeds)\n",
    "    dst_latents = np.stack(np.random.RandomState(seed).randn(Gs.input_shape[1]) for seed in dst_seeds)\n",
    "    src_dlatents = Gs.components.mapping.run(src_latents, None) # [seed, layer, component]\n",
    "    dst_dlatents = Gs.components.mapping.run(dst_latents, None) # [seed, layer, component]\n",
    "    src_images = Gs.components.synthesis.run(src_dlatents, randomize_noise=False, **synthesis_kwargs)\n",
    "    dst_images = Gs.components.synthesis.run(dst_dlatents, randomize_noise=False, **synthesis_kwargs)\n",
    "\n",
    "    canvas = PIL.Image.new('RGB', (w * (len(src_seeds)), h * (len(dst_seeds))), 'white')\n",
    "    #for col, src_image in enumerate(list(src_images)):\n",
    "    for row, dst_image in enumerate(list(dst_images)):\n",
    "        #canvas.paste(PIL.Image.fromarray(dst_image, 'RGB'), (0, (row + 1) * h))\n",
    "        row_dlatents = np.stack([dst_dlatents[row]] * len(src_seeds))\n",
    "        row_dlatents[:, style_ranges[row]] = src_dlatents[:, style_ranges[row]]\n",
    "        row_images = Gs.components.synthesis.run(row_dlatents, randomize_noise=False, **synthesis_kwargs)\n",
    "        for col, image in enumerate(list(row_images)):\n",
    "            canvas.paste(PIL.Image.fromarray(image, 'RGB'), ((col) * w, (row) * h))\n",
    "    return canvas\n",
    "\n",
    "\n",
    "\n",
    "def draw_noise_detail_figure(png, Gs, w, h, num_samples, seeds):\n",
    "    canvas = PIL.Image.new('RGB', (w * 3, h * len(seeds)), 'white')\n",
    "    for row, seed in enumerate(seeds):\n",
    "        latents = np.stack([np.random.RandomState(seed).randn(Gs.input_shape[1])] * num_samples)\n",
    "        images = Gs.run(latents, None, truncation_psi=1, **synthesis_kwargs)\n",
    "        canvas.paste(PIL.Image.fromarray(images[0], 'RGB'), (0, row * h))\n",
    "        for i in range(4):\n",
    "            crop = PIL.Image.fromarray(images[i + 1], 'RGB')\n",
    "            crop = crop.crop((650, 180, 906, 436))\n",
    "            crop = crop.resize((w//2, h//2), PIL.Image.NEAREST)\n",
    "            canvas.paste(crop, (w + (i%2) * w//2, row * h + (i//2) * h//2))\n",
    "        diff = np.std(np.mean(images, axis=3), axis=0) * 4\n",
    "        diff = np.clip(diff + 0.5, 0, 255).astype(np.uint8)\n",
    "        canvas.paste(PIL.Image.fromarray(diff, 'L'), (w * 2, row * h))\n",
    "    return canvas\n",
    "\n",
    "def draw_noise_components_figure(png, Gs, w, h, seeds, noise_ranges, flips):\n",
    "    Gsc = Gs.clone()\n",
    "    noise_vars = [var for name, var in Gsc.components.synthesis.vars.items() if name.startswith('noise')]\n",
    "    noise_pairs = list(zip(noise_vars, tflib.run(noise_vars))) # [(var, val), ...]\n",
    "    latents = np.stack(np.random.RandomState(seed).randn(Gs.input_shape[1]) for seed in seeds)\n",
    "    all_images = []\n",
    "    for noise_range in noise_ranges:\n",
    "        tflib.set_vars({var: val * (1 if i in noise_range else 0) for i, (var, val) in enumerate(noise_pairs)})\n",
    "        range_images = Gsc.run(latents, None, truncation_psi=1, randomize_noise=False, **synthesis_kwargs)\n",
    "        range_images[flips, :, :] = range_images[flips, :, ::-1]\n",
    "        all_images.append(list(range_images))\n",
    "\n",
    "    canvas = PIL.Image.new('RGB', (w * 2, h * 2), 'white')\n",
    "    for col, col_images in enumerate(zip(*all_images)):\n",
    "        canvas.paste(PIL.Image.fromarray(col_images[0], 'RGB').crop((0, 0, w//2, h)), (col * w, 0))\n",
    "        canvas.paste(PIL.Image.fromarray(col_images[1], 'RGB').crop((w//2, 0, w, h)), (col * w + w//2, 0))\n",
    "        canvas.paste(PIL.Image.fromarray(col_images[2], 'RGB').crop((0, 0, w//2, h)), (col * w, h))\n",
    "        canvas.paste(PIL.Image.fromarray(col_images[3], 'RGB').crop((w//2, 0, w, h)), (col * w + w//2, h))\n",
    "    return canvas\n",
    "\n",
    "def draw_image(seed,Gs):\n",
    "    latents = np.random.RandomState(seed).randn(1,Gs.input_shape[1])\n",
    "    dlatents = np.stack(Gs.components.mapping.run(latents, None)) # [seed, layer, component]\n",
    "    canvas = PIL.Image.fromarray(Gs.components.synthesis.run(dlatents, randomize_noise=True, **synthesis_kwargs)[0],'RGB',format='jpg')\n",
    "    return canvas.resize((256,256))\n",
    "\n",
    "def draw_truncation_trick_figure(png, Gs, w, h, seeds, psis):\n",
    "    latents = np.stack(np.random.RandomState(seed).randn(Gs.input_shape[1]) for seed in seeds)\n",
    "    dlatents = Gs.components.mapping.run(latents, None) # [seed, layer, component]\n",
    "    dlatent_avg = Gs.get_var('dlatent_avg') # [component]\n",
    "\n",
    "    canvas = PIL.Image.new('RGB', (w * len(psis), h * len(seeds)), 'white')\n",
    "    for row, dlatent in enumerate(list(dlatents)):\n",
    "        row_dlatents = (dlatent[np.newaxis] - dlatent_avg) * np.reshape(psis, [-1, 1, 1]) + dlatent_avg\n",
    "        row_images = Gs.components.synthesis.run(row_dlatents, randomize_noise=False, **synthesis_kwargs)\n",
    "        for col, image in enumerate(list(row_images)):\n",
    "            canvas.paste(PIL.Image.fromarray(image, 'RGB'), (col * w, row * h))\n",
    "    return canvas\n",
    "\n",
    "def make_movie(images, out_dir, out_name):\n",
    "    temp_dir = 'frames%06d'%int(1000000*random.random())\n",
    "    os.system('mkdir %s'%temp_dir)\n",
    "    for idx in tqdm(range(len(images))):\n",
    "        PIL.Image.fromarray(images[idx], 'RGB').save('%s/frame%05d.png' % (temp_dir, idx))\n",
    "    cmd = 'ffmpeg -i %s/frame%%05d.png -c:v libx264 -pix_fmt yuv420p %s.mp4' % (temp_dir,  out_name)\n",
    "    print(cmd)\n",
    "    os.system(cmd)\n",
    "    os.system('del /S %s'%temp_dir)\n",
    "\n",
    "def generate_image(latent_vector, Gs):\n",
    "    latent_vector = latent_vector.reshape((1, 18, 512))\n",
    "    img_array = Gs.components.synthesis.run(latent_vector, randomize_noise=False, **synthesis_kwargs)[0]\n",
    "    return img_array  \n",
    "\n",
    "def move_and_show(latent_vector, Gs, direction, frames, rangestart, rangeend):\n",
    "    step = (rangeend - rangestart) / frames\n",
    "    output = []\n",
    "    for i in range(0,frames):\n",
    "        coeff = rangestart + ( step * i )\n",
    "        new_latent_vector = latent_vector.copy()\n",
    "        new_latent_vector[:18] = (latent_vector + coeff*direction)[:18]\n",
    "        output.append(generate_image(new_latent_vector, Gs))\n",
    "    return output\n",
    "    \n",
    "def draw_image_from_latents(latents,Gs):\n",
    "    dlatents = latents.reshape((1, 18, 512))\n",
    "    canvas = PIL.Image.fromarray(Gs.components.synthesis.run(dlatents, randomize_noise=False, **synthesis_kwargs)[0],'RGB')\n",
    "    return canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINED_DIRECTIONS = \"/home/firschj/src/CS548_Research_Code_GAN/stylegan2/trained_directions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_direction = np.load(os.path.join(TRAINED_DIRECTIONS, 'gender_direction.npy'))\n",
    "s_gender = widgets.FloatSlider(\n",
    "    value=0,\n",
    "    min=-3,\n",
    "    max=3.0,\n",
    "    step=0.1,\n",
    "    description='Gender:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='.2f',\n",
    "    layout=widgets.Layout(width='900px',height='10px')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "headPose_yaw_direction = np.load(os.path.join(TRAINED_DIRECTIONS, 'headPose_yaw_direction.npy'))\n",
    "s_headPose_yaw = widgets.FloatSlider(\n",
    "    value=0,\n",
    "    min=-3,\n",
    "    max=3.0,\n",
    "    step=0.1,\n",
    "    description='yaw:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='.2f',\n",
    "    layout=widgets.Layout(width='900px',height='10px')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "headPose_roll_direction = np.load(os.path.join(TRAINED_DIRECTIONS, 'headPose_roll_direction.npy'))\n",
    "s_headPose_roll = widgets.FloatSlider(\n",
    "    value=0,\n",
    "    min=-3,\n",
    "    max=3.0,\n",
    "    step=0.1,\n",
    "    description='roll:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='.2f',\n",
    "    layout=widgets.Layout(width='900px',height='10px')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_kid_direction = np.load(os.path.join(TRAINED_DIRECTIONS, 'age_kid_direction.npy'))\n",
    "s_age_kid = widgets.FloatSlider(\n",
    "    value=0,\n",
    "    min=-3,\n",
    "    max=3.0,\n",
    "    step=0.1,\n",
    "    description='age_kid:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='.2f',\n",
    "    layout=widgets.Layout(width='900px',height='10px')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_middle_direction = np.load(os.path.join(TRAINED_DIRECTIONS, 'age_middle_direction.npy'))\n",
    "s_age_middle = widgets.FloatSlider(\n",
    "    value=0,\n",
    "    min=-3,\n",
    "    max=3.0,\n",
    "    step=0.1,\n",
    "    description='age_middle:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='.2f',\n",
    "    layout=widgets.Layout(width='900px',height='10px')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_young_direction = np.load(os.path.join(TRAINED_DIRECTIONS, 'age_young_direction.npy'))\n",
    "s_age_young = widgets.FloatSlider(\n",
    "    value=0,\n",
    "    min=-3,\n",
    "    max=3.0,\n",
    "    step=0.1,\n",
    "    description='age_young:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='.2f',\n",
    "    layout=widgets.Layout(width='900px',height='10px')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_old_direction = np.load(os.path.join(TRAINED_DIRECTIONS, 'age_old_direction.npy'))\n",
    "s_age_old = widgets.FloatSlider(\n",
    "    value=0,\n",
    "    min=-3,\n",
    "    max=3.0,\n",
    "    step=0.1,\n",
    "    description='age_old:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='.2f',\n",
    "    layout=widgets.Layout(width='900px',height='10px')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "glasses_direction = np.load(os.path.join(TRAINED_DIRECTIONS, 'glasses_direction.npy'))\n",
    "s_glasses = widgets.FloatSlider(\n",
    "    value=0,\n",
    "    min=-3,\n",
    "    max=3.0,\n",
    "    step=0.1,\n",
    "    description='glasses:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='.2f',\n",
    "    layout=widgets.Layout(width='900px',height='10px')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "smile_direction = np.load(os.path.join(TRAINED_DIRECTIONS, 'smile_direction.npy'))\n",
    "s_smile = widgets.FloatSlider(\n",
    "    value=0,\n",
    "    min=-3,\n",
    "    max=3.0,\n",
    "    step=0.1,\n",
    "    description='smile:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='.2f',\n",
    "    layout=widgets.Layout(width='900px',height='10px')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "anger_direction = np.load(os.path.join(TRAINED_DIRECTIONS, 'anger_direction.npy'))\n",
    "s_anger = widgets.FloatSlider(\n",
    "    value=0,\n",
    "    min=-3,\n",
    "    max=3.0,\n",
    "    step=0.1,\n",
    "    description='anger:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='.2f',\n",
    "    layout=widgets.Layout(width='900px',height='10px')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sadness_direction = np.load(os.path.join(TRAINED_DIRECTIONS, 'sadness_direction.npy'))\n",
    "s_sadness = widgets.FloatSlider(\n",
    "    value=0,\n",
    "    min=-3,\n",
    "    max=3.0,\n",
    "    step=0.1,\n",
    "    description='sadness:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='.2f',\n",
    "    layout=widgets.Layout(width='900px',height='10px')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/firschj/src/CS548_Research_Code_GAN/stylegan2/trained_directions/contempt_direction.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-7b3d11141d1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcontempt_direction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAINED_DIRECTIONS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'contempt_direction.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/SORCERY/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    414\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/firschj/src/CS548_Research_Code_GAN/stylegan2/trained_directions/contempt_direction.npy'"
     ]
    }
   ],
   "source": [
    "contempt_direction = np.load(os.path.join(TRAINED_DIRECTIONS, 'contempt_direction.npy'))\n",
    "s_contempt = widgets.FloatSlider(\n",
    "    value=0,\n",
    "    min=-3,\n",
    "    max=3.0,\n",
    "    step=0.1,\n",
    "    description='contempt:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='.2f',\n",
    "    layout=widgets.Layout(width='900px',height='10px')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/firschj/src/CS548_Research_Code_GAN/stylegan2/trained_directions/disgust_direction.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-4dc57caf5fc0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdisgust_direction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAINED_DIRECTIONS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'disgust_direction.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/SORCERY/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    414\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/firschj/src/CS548_Research_Code_GAN/stylegan2/trained_directions/disgust_direction.npy'"
     ]
    }
   ],
   "source": [
    "disgust_direction = np.load(os.path.join(TRAINED_DIRECTIONS, 'disgust_direction.npy'))\n",
    "s_disgust = widgets.FloatSlider(\n",
    "    value=0,\n",
    "    min=-3,\n",
    "    max=3.0,\n",
    "    step=0.1,\n",
    "    description='disgust:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='.2f',\n",
    "    layout=widgets.Layout(width='900px',height='10px')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/firschj/src/CS548_Research_Code_GAN/stylegan2/trained_directions/fear_direction.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-601b7955457e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfear_direction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAINED_DIRECTIONS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fear_direction.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/SORCERY/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    414\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/firschj/src/CS548_Research_Code_GAN/stylegan2/trained_directions/fear_direction.npy'"
     ]
    }
   ],
   "source": [
    "fear_direction = np.load(os.path.join(TRAINED_DIRECTIONS, 'fear_direction.npy'))\n",
    "s_fear = widgets.FloatSlider(\n",
    "    value=0,\n",
    "    min=-3,\n",
    "    max=3.0,\n",
    "    step=0.1,\n",
    "    description='fear:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='.2f',\n",
    "    layout=widgets.Layout(width='900px',height='10px')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "happiness_direction = np.load(os.path.join(TRAINED_DIRECTIONS, 'happiness_direction.npy'))\n",
    "s_happiness = widgets.FloatSlider(\n",
    "    value=0,\n",
    "    min=-3,\n",
    "    max=3.0,\n",
    "    step=0.1,\n",
    "    description='happiness:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='.2f',\n",
    "    layout=widgets.Layout(width='900px',height='10px')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "neutral_direction = np.load(os.path.join(TRAINED_DIRECTIONS, 'neutral_direction.npy'))\n",
    "s_neutral = widgets.FloatSlider(\n",
    "    value=0,\n",
    "    min=-3,\n",
    "    max=3.0,\n",
    "    step=0.1,\n",
    "    description='neutral:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='.2f',\n",
    "    layout=widgets.Layout(width='900px',height='10px')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/firschj/src/CS548_Research_Code_GAN/stylegan2/trained_directions/surprise_direction.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-f7b883c3ab89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msurprise_direction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAINED_DIRECTIONS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'surprise_direction.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/SORCERY/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    414\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/firschj/src/CS548_Research_Code_GAN/stylegan2/trained_directions/surprise_direction.npy'"
     ]
    }
   ],
   "source": [
    "surprise_direction = np.load(os.path.join(TRAINED_DIRECTIONS, 'surprise_direction.npy'))\n",
    "s_surprise = widgets.FloatSlider(\n",
    "    value=0,\n",
    "    min=-3,\n",
    "    max=3.0,\n",
    "    step=0.1,\n",
    "    description='surprise:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='.2f',\n",
    "    layout=widgets.Layout(width='900px',height='10px')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "eyeMakeup_direction = np.load(os.path.join(TRAINED_DIRECTIONS, 'eyeMakeup_direction.npy'))\n",
    "s_eyeMakeup = widgets.FloatSlider(\n",
    "    value=0,\n",
    "    min=-3,\n",
    "    max=3.0,\n",
    "    step=0.1,\n",
    "    description='eyeMakeup:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='.2f',\n",
    "    layout=widgets.Layout(width='900px',height='10px')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lipMakeup_direction = np.load(os.path.join(TRAINED_DIRECTIONS, 'lipMakeup_direction.npy'))\n",
    "s_lipMakeup = widgets.FloatSlider(\n",
    "    value=0,\n",
    "    min=-3,\n",
    "    max=3.0,\n",
    "    step=0.1,\n",
    "    description='lipMakeup:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='.2f',\n",
    "    layout=widgets.Layout(width='900px',height='10px')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "beard_direction = np.load(os.path.join(TRAINED_DIRECTIONS, 'beard_direction.npy'))\n",
    "s_beard = widgets.FloatSlider(\n",
    "    value=0,\n",
    "    min=-3,\n",
    "    max=3.0,\n",
    "    step=0.1,\n",
    "    description='beard:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='.2f',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "moustache_direction = np.load(os.path.join(TRAINED_DIRECTIONS, 'moustache_direction.npy'))\n",
    "s_moustache = widgets.FloatSlider(\n",
    "    value=0,\n",
    "    min=-3,\n",
    "    max=3.0,\n",
    "    step=0.1,\n",
    "    description='moustache:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='.2f',\n",
    "    layout=widgets.Layout(width='900px',height='10px')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sideburns_direction = np.load(os.path.join(TRAINED_DIRECTIONS, 'sideburns_direction.npy'))\n",
    "s_sideburns = widgets.FloatSlider(\n",
    "    value=0,\n",
    "    min=-3,\n",
    "    max=3.0,\n",
    "    step=0.1,\n",
    "    description='sideburns:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='.2f',\n",
    "    layout=widgets.Layout(width='900px',height='10px')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tflib.init_tf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slider( gender,\n",
    "            headPose_yaw,\n",
    "            headPose_roll,\n",
    "            age_kid,\n",
    "            age_middle,\n",
    "            age_young,\n",
    "            age_old,\n",
    "            glasses,\n",
    "            smile,\n",
    "            anger,\n",
    "            sadness,\n",
    "#             contempt,\n",
    "#             fear,\n",
    "            happiness,\n",
    "#             neutral,\n",
    "#             surprise,\n",
    "#             disgust,\n",
    "            eyeMakeup,\n",
    "            lipMakeup,\n",
    "            beard,\n",
    "            moustache,\n",
    "            sideburns\n",
    "                   \n",
    "          ):\n",
    "    latents = np.zeros((18,512))\n",
    "    latents = latents  + (  \n",
    "                                gender*gender_direction\n",
    "                                + headPose_yaw*headPose_yaw_direction\n",
    "                                - headPose_roll*headPose_roll_direction\n",
    "                                + eyeMakeup*eyeMakeup_direction\n",
    "                                + lipMakeup*lipMakeup_direction\n",
    "                                - age_kid*age_kid_direction\n",
    "                                + age_middle*age_middle_direction\n",
    "                                - age_young*age_young_direction\n",
    "                                + age_old*age_old_direction\n",
    "                                + glasses*glasses_direction\n",
    "                                + smile*smile_direction\n",
    "                                + anger*anger_direction\n",
    "                                + sadness*sadness_direction\n",
    "#                                 + contempt*contempt_direction\n",
    "#                                 + fear*fear_direction\n",
    "                                + happiness*happiness_direction\n",
    "#                                 + neutral*neutral_direction\n",
    "#                                 + surprise*surprise_direction\n",
    "#                                 + disgust*disgust_direction                   \n",
    "                                + beard*beard_direction\n",
    "                                + moustache*moustache_direction\n",
    "                                + sideburns*sideburns_direction\n",
    "                                )\n",
    "    \n",
    "    image = draw_image_from_latents(latents,load_Gs(url_ffhq))\n",
    "    display(image.resize((256,256)))\n",
    "    return image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "024dd3ff15f14ba9b0f6f9f07d507d62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=1.8, continuous_update=False, description='Gender:', layout=Layout(hei…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "w= interactive(slider, \n",
    "                gender = s_gender,\n",
    "                glasses = s_glasses,\n",
    "                headPose_yaw = s_headPose_yaw,\n",
    "                headPose_roll = s_headPose_roll,\n",
    "                age_kid = s_age_kid,\n",
    "                age_middle = s_age_middle,\n",
    "                age_young = s_age_young,\n",
    "                age_old = s_age_old,\n",
    "                smile = s_smile,\n",
    "                anger = s_anger,\n",
    "                sadness = s_sadness,\n",
    "#                 contempt = s_contempt,\n",
    "#                 fear = s_fear,\n",
    "                happiness = s_happiness,\n",
    "#                 neutral = s_neutral,\n",
    "#                 surprise = s_surprise,\n",
    "#                 disgust = s_disgust,\n",
    "                eyeMakeup = s_eyeMakeup,\n",
    "                lipMakeup = s_lipMakeup, \n",
    "                beard = s_beard,                \n",
    "                moustache = s_moustache,               \n",
    "                sideburns = s_sideburns,                 \n",
    "               );\n",
    "\n",
    "display(w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
